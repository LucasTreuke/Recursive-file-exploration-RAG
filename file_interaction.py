from langchain_core.language_models.base import BaseLanguageModel
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from utils import State, render_prompt, format_current_context, image_to_base64
import json
from typing import List

class FileInteractionAgent:
    def get_context_from_file(self, specific_prompt: str, file_path: str, state: State) -> str:
        pass

class TextReaderAgent(FileInteractionAgent):
    """
    Agent responsible to read a given text file and get the relevant information from it.
    """
    def __init__(self, llm: BaseLanguageModel, prompt_path: str, treat_errors: bool = True):
        """
        Args:
            llm (BaseLanguageModel): the language model to be used to generate the answer
            prompt_path (str): the path to the prompt file
            treat_errors (bool): if True, the agent will treat errors and return a message instead of raising an exception
        """
        self.llm = llm
        self.prompt_path = prompt_path
        self.treat_errors = treat_errors

    def get_file_content(self, file_path: str) -> str:
        try:
            with open(file_path, 'r', encoding="utf-8") as file:
                return file.read()
        except Exception as e:
            print(f"An error occurred while reading the file: {str(e)}")
            print(file_path)
            raise e
    def get_context_from_file(self, specific_prompt: str, file_path: str, state: State) -> str:
        main_prompt = state.get('main_prompt', 'there is no main prompt')
        current_context = format_current_context(state)
        try:
            file_content = self.get_file_content(file_path)
        except Exception as e:
            if self.treat_errors:
                file_content = f"An error occurred while reading the file, if you can get any insight of why this error happened give as feedback in the answer so that the problem wont happen again: {str(e)}"
            else:
                raise e

        prompt_variables = {
            "main_prompt" : main_prompt,
            "current_context" : current_context,
            "file_path": file_path,
            "specific_prompt" : specific_prompt,
            "file_content" : file_content
        }
        prompt = render_prompt(self.prompt_path, prompt_variables)

        try:
            result = self.generate_answer(prompt)
        except Exception as e:
            if self.treat_errors:
                result = f"An error occured while generating the answer: {str(e)}"
            else:
                raise e
            
        return result
    
    def generate_answer(self, prompt):
        return self.llm.invoke(prompt).content

from pandasql import sqldf
import pandas as pd

class DataReaderAgent(FileInteractionAgent):
    """
    Agent responsible to read a given text file and get the relevant information from it.

    This class uses the pandasql library to execute the queries generated by the language model.
    It also expects that the agent has structured output, to use pydantic to define the format of the answer.
    """
    def __init__(self, llm: BaseLanguageModel, prompt_path: str, treat_errors: bool = True):
        """
        Args:
            llm (BaseLanguageModel): the language model to be used to generate the answer
            prompt_path (str): the path to the prompt file
            treat_errors (bool): if True, the agent will treat errors and return a message instead of raising an exception
        """

        # Define the format of the answer as a dict like this:
        # {
        #     "query": "Generated SQLite query"
        # }
        class PydanticQuery(BaseModel):
            query: str = Field(description="Generated SQLite query")
        
        self.llm = llm
        self.query_gen_llm = llm.with_structured_output(PydanticQuery)
        
        self.prompt_path = prompt_path
        self.treat_errors = treat_errors

    def get_file_content(self, file_path: str) -> pd.DataFrame:
        """
        Reads a file and returns its content as a pandas dataframe with the columns
        formatted as lower case and with underscores instead of spaces.

        Args:
            file_path (str): the path to the file

        Returns:
            pd.DataFrame: the content of the file as a pandas dataframe
        """
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        elif file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        elif file_path.endswith('.parquet'):
            df = pd.read_parquet(file_path)
        else:
            raise ValueError(f"Unsupported file format: {file_path}")
        
        # transform column names to lower case and replace spaces with underscores
        df.columns = [col.replace(' ', '_').lower() for col in df.columns]
        for col in df.columns:
            if df[col].dtype == 'object':
                df[col] = df[col].astype(str)
        
        return df

    def get_dataframe_summary(self, df: pd.DataFrame, table_name) -> str:
        """
        Returns a summary of the dataframe treating it as a table.

        Args:
            df (pd.DataFrame): the dataframe to be summarized
            table_name (str): the name of the table

        Returns:
            str: the summary of the dataframe
        """

        summary = f"""
        summary of the table {table_name}: {df.shape[0]} rows and {df.shape[1]} columns

        columns:
        """
        for col in df.columns:
            column_type = df[col].dtype
            if column_type == 'object':
                column_type = 'string'
            
            if column_type in ['int64', 'float64']:
                extra = f", min: {df[col].min()}, max: {df[col].max()}"
            else:
                extra = ""

            summary += f"{col} ({column_type})" + extra + "\n"

        summary += f"""
        the first 5 rows are:
        {df.head()}
        """
        return summary

    def get_context_from_file(self, specific_prompt: str, file_path: str, state: State) -> str:
        main_prompt = state.get('main_prompt', 'there is no main prompt')
        current_context = format_current_context(state)
        table_name = file_path.split('/')[-1].split('.')[0]
        table_name = table_name.replace(' ', '_').lower() + '_table'
        try:
            local_df_variable = self.get_file_content(file_path)
        except Exception as e:
            if self.treat_errors:
                return f"An error occurred while reading the file, if you can get any insight of why this error happened give as feedback in the answer so that the problem wont happen again: {str(e)}"
            else:
                raise e
        
        table_summary = self.get_dataframe_summary(local_df_variable, table_name)

        prompt_variables = {
            "main_prompt" : main_prompt,
            "current_context" : current_context,
            "file_path": file_path,
            "table_name": table_name,
            "table_summary": table_summary,
            "specific_prompt" : specific_prompt
        }
        prompt = render_prompt(self.prompt_path, prompt_variables)

        try:
            generated_query = self.generate_answer(prompt)

            # format the query, substituting the table name
            query = generated_query.replace(table_name, 'local_df_variable')
            
            # execute the query, this will execute the query on the local_df_variable table
            try:
                result = sqldf(query, locals())
            except Exception as e:
                if self.treat_errors:
                    result = f"An error occurred while executing the query: {str(e)}\n\nPlease consider giving feedback on the answer so that the problem won't happen again."
                else:
                    raise e
            
            # formating the result to output it as a resulting context generated from the file
            result = f"""
            {table_summary}

            the query generated was:
            ```sql
            {generated_query}
            ```

            and the result of the query is:
            {result}
            """

        except Exception as e:
            if self.treat_errors:
                result = f"An error occured while generating the answer: {str(e)}"
            else:
                raise e
            
        return result
    
    def generate_answer(self, prompt):
        """
        Generates a query based on the given prompt.
        """
        answer = self.query_gen_llm.invoke(prompt)
        if answer is None:
            answer = self.llm.invoke(prompt)
            answer = json.loads(answer.content)
            query = answer['query']
        else:
            query = answer.query

        return query

class NotebookReaderAgent(FileInteractionAgent):
    """
    Agent responsible to read a given jupyter notebook file and get the relevant information from it.

    This class answers the question by generating the answer using the language model, adding both the textual content of the notebook that is relevant, and also the image descriptions of the relevant images.
    """
    def __init__(self, llm: BaseLanguageModel, prompt_path: str, treat_errors: bool = True, vision_llm: BaseLanguageModel = None):
        """
        Args:
            llm (BaseLanguageModel): the language model to be used to generate the answer
            prompt_path (str): the path to the prompt file
            treat_errors (bool): if True, the agent will treat errors and return a message instead of raising an exception
        """

        # Define the format of the answer as a dict like this:
        # {
        #     "relevant_content": "Relevant content from the notebook",
        #     "image_questions": ["Dictionay with image ids, and prompts asking for insights"]
        # }
        class PydanticNotebookContent(BaseModel):
            relevant_content: str = Field(description="Relevant content from the notebook")
            image_questions: dict = Field(description="Dictionay with image ids, and prompts asking for insights")
        
        self.llm = llm
        if vision_llm is None:
            self.vision_llm = llm
        else:
            self.vision_llm = vision_llm

        self.structured_output_llm = llm.with_structured_output(PydanticNotebookContent)
        
        self.prompt_path = prompt_path
        self.treat_errors = treat_errors

    def get_next_image_id(self, images):
            prefix = "figure_"
            if len(images) == 0:
                return prefix + "0"

            fig_id = prefix + str( len(images) )
            if fig_id not in images:
                return fig_id

    def preprocess_notebook(self, notebook_str_content: str) -> dict:
        """
        Transformrs the raw notebook data to a more legible format.
        Also extracts the images from the notebook.
        """
        notebook = json.loads(notebook_str_content)
        notebooks_cells = []
        notebook_images = {}

        notebook_content = ""
        for cell in notebook["cells"]:
            if cell["cell_type"] == "markdown":
                cell_content = cell["source"]
                if cell_content and len(cell_content) > 0:
                    cell_content = "".join(cell_content)
                    notebooks_cells.append({
                        "cell_tp": "markdown",
                        "cell_content": cell_content
                    })
            
            elif cell["cell_type"] == "code":
                code_cell = {}

                source_content = cell["source"]
                if source_content and len(source_content) > 0:
                    source_content = "".join(source_content)
                    code_cell["source"] = source_content

                output_content = cell["outputs"]
                if output_content and len(output_content) > 0:
                    cell_output = ""
                    for output in output_content:
                        if "text" in output:
                            cell_output += "".join(output["text"])

                        if "data" in output and "image/png" in output["data"]:
                            image = output["data"]["image/png"]
                            fig_id = self.get_next_image_id(notebook_images)
                            notebook_images[fig_id] = image
                            cell_output += f"[[figure_id = {fig_id}]]\n"
                        
                    code_cell["output"] = cell_output

                notebooks_cells.append({
                    "cell_tp": "code",
                    "cell_content": code_cell
                })

        for cell in notebooks_cells:
            if cell["cell_tp"] == "markdown":
                notebook_content += "\n<markdown>\n" + cell["cell_content"] + "\n</markdown>\n"
            elif cell["cell_tp"] == "code":
                code_cell = cell["cell_content"]
                notebook_content += "\n<code>\n" + code_cell["source"] + "\n</code>\n"
                if "output" in code_cell:
                    notebook_content += "<output>\n" + code_cell["output"] + "\n</output>\n"
        
        return {
            "notebook_content": notebook_content,
            "notebook_images": notebook_images
        }

    def get_file_content(self, file_path: str) -> dict:
        try:
            with open(file_path, 'r', encoding="utf-8") as file:
                return file.read()
        except Exception as e:
            print(f"An error occurred while reading the file: {str(e)}")
            print(file_path)
            raise e
    
    def get_image_description(self, image_id: str, image_prompt: str, base64_image: str) -> dict:
        """
        Generates a prompt to ask for a description of an image.
        """
        prompt = f"""
        Describe the image image, with figure_id = {image_id} and focus on bringing insights that are possible to get from the image interpretation and answer the following question:
        {image_prompt}
        """
        messages = [HumanMessage(
            content=[
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url":  f"data:image/jpeg;base64,{base64_image}"
                    },
                },
            ],
        )]
        img_answer = self.vision_llm.invoke(messages).content
        img_answer = f"\n[description of image with figure_id = {image_id}]\n prompt:{prompt}\n\nresult:\n{img_answer} \n[end of image description]\n"

        return img_answer 

    def get_context_from_file(self, specific_prompt: str, file_path: str, state: State) -> str:
        main_prompt = state.get('main_prompt', 'there is no main prompt')
        current_context = format_current_context(state)
        try:
            file_content = self.get_file_content(file_path)
            notebook_data = self.preprocess_notebook(file_content)
        except Exception as e:
            if self.treat_errors:
                file_content = f"An error occurred while reading the file, if you can get any insight of why this error happened give as feedback in the answer so that the problem wont happen again: {str(e)}"
            else:
                raise e
            
        notebook_images = notebook_data["notebook_images"]
        notebook_content = notebook_data["notebook_content"]

        prompt_variables = {
            "main_prompt" : main_prompt,
            "current_context" : current_context,
            "file_path": file_path,
            "specific_prompt" : specific_prompt,
            "notebook_content" : notebook_content,
        }
        prompt = render_prompt(self.prompt_path, prompt_variables)
        
        try:
            result = self.generate_answer(prompt)
        
            relevant_notebook_content = result["relevant_content"]
            relevant_images = result["image_questions"]

            for image_id, image_prompt in relevant_images.items():
                image = notebook_images.get(image_id, None)
                if image is not None:
                    img_answer = self.get_image_description(image_id, image_prompt, image)

                    relevant_notebook_content += "\n"+img_answer+"\n"
                else:
                    relevant_notebook_content += f"\nImage with figure_id = {image_id} was not found in the notebook\n"

        except Exception as e:
            if self.treat_errors:
                relevant_notebook_content = f"An error occured while generating the answer: {str(e)}"
            else:
                raise e
            
        return relevant_notebook_content
    
    def generate_answer(self, prompt):
        result = self.structured_output_llm.invoke(prompt)
        relevant_notebook_content = {}
        if result is None:
            result = self.llm.invoke(prompt)
            result = json.loads(result.content)
            relevant_notebook_content["relevant_content"] = result["relevant_content"]
            relevant_notebook_content["image_questions"] = result["image_questions"]
        else:
            relevant_notebook_content["relevant_content"] = result.relevant_content
            relevant_notebook_content["image_questions"] = result.image_questions
        
        return relevant_notebook_content
    
class ImageReaderAgent(FileInteractionAgent):
    """
    Agent responsible to read a given image file and get the relevant information from it.

    This agent uses a vision-capable language model to analyze and interpret images.
    """
    def __init__(self, vision_llm: BaseLanguageModel, prompt_path: str = '', treat_errors: bool = True):
        """
        Args:
            vision_llm (BaseLanguageModel): A language model capable of image analysis and vision tasks.
            prompt_path (str): The path to the prompt template.
            treat_errors (bool): If True, errors will be caught and formatted into feedback instead of raising exceptions.
        """
        self.vision_llm = vision_llm
        self.prompt_path = prompt_path
        self.treat_errors = treat_errors

    def get_image_description(self, image_path: str, specific_prompt: str, main_prompt: str, current_context: str) -> str:
        """
        Generates a description of the image based on a specific prompt.

        Args:
            image_path (str): Path to the image file.
            specific_prompt (str): Specific question or focus for image analysis.

        Returns:
            str: A detailed description or insight about the image.
        """
        try:
            base64_image = image_to_base64(image_path)

            prompt = f"""
            Focus on the following question while analyzing the image:
            {specific_prompt}
            Also, provide helpful information that's on the image and can help with answering this broader question.:
            '{main_prompt}'

            [[Current knowledge of the project]]
            {{current_context}}
            [[End of current knowledge]]

            Provide insights that are possible to extract from the image.
            """

            messages = [HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                ]
            )]

            result = self.vision_llm.invoke(messages).content
            formatted_result = f"""
            Prompt: '{specific_prompt}'
            
            Result:
            {result}
            """
            return formatted_result

        except Exception as e:
            if self.treat_errors:
                return f"An error occurred while analyzing the image: {str(e)}"
            else:
                raise e

    def get_context_from_file(self, specific_prompt: str, file_path: str, state: State) -> str:
        """
        Provides relevant information from the image file based on the context and specific prompt.

        Args:
            specific_prompt (str): Specific question or instruction.
            file_path (str): Path to the image file.
            state (State): State containing context and history.

        Returns:
            str: Generated insights from the image.
        """
        main_prompt = state.get('main_prompt', 'there is no main prompt')
        current_context = format_current_context(state)

        try:
            image_description = self.get_image_description(file_path, specific_prompt, main_prompt, current_context)
        except Exception as e:
            if self.treat_errors:
                image_description = f"An error occurred while analyzing the image: {str(e)}"
            else:
                raise e

        return f"""
        [[Visual Analysis of the image at {file_path}]]
        {image_description}
        [[End of Visual Analysis]]
        """
